{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# numpy, pandas, sklearn; the bootstrap function np.random.choice with repetition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def sub_samples(dataset, k, bootstrap = True):\n",
    "    m, n = dataset.shape\n",
    "    if bootstrap:\n",
    "        indexes = np.random.choice(m, k)\n",
    "        sub_samples = dataset[indexes]\n",
    "    else:\n",
    "        indexes = np.random.permutation(m)[:k]\n",
    "        sub_samples = dataset[indexes]\n",
    "    return sub_samples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# decision stump function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_dataset(dataset, split_feature, split_value):\n",
    "    right_sub = dataset[np.nonzero(dataset[:, split_feature] > split_value)[0], :]\n",
    "    left_sub = dataset[np.nonzero(dataset[:, split_feature] < split_value)[0], :]\n",
    "    return right_sub, left_sub"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# variance: the regression score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "def regression_error_leaf(sub):\n",
    "    return np.var(sub[:, -1])*sub.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# mean value for each leaf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "def leaf_value(sub):\n",
    "    return np.mean(sub[:, -1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# select the best feature: select NO. feature_num of features from the total NO. of features; if scores are too close, return no feature but the leaf mean value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_best_feature(dataset, feature_num, key = 'regression'):\n",
    "    n = dataset.shape[1]\n",
    "    best_score = inf\n",
    "    best_feature = 0\n",
    "    best_value = 0\n",
    "    indexes = []\n",
    "    if key == 'regression':\n",
    "        S = regression_error_leaf(dataset)\n",
    "    for num in range(feature_num):\n",
    "        indexes.append(np.random.randint(n - 1))\n",
    "    for i in indexes:\n",
    "        for j in set(dataset[:, i]):\n",
    "            right_sub, left_sub = split_dataset(dataset, i, j)\n",
    "            if key == 'regression':\n",
    "                S_temp = regression_error_leaf(right_sub) + regression_error_leaf(left_sub)\n",
    "            if S_temp < best_score:\n",
    "                best_score = S_temp\n",
    "                best_feature = i\n",
    "                best_value = j\n",
    "    if (S - best_score) < 0.001 and key == 'regression':\n",
    "        return leaf_value(dataset), None\n",
    "    return best_value, best_feature"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# create a single tree, with max depth 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_single_tree(dataset, feature_num, key = 'regression', max_depth = 20):\n",
    "    best_value, best_feature = select_best_feature(dataset, feature_num, key = key)\n",
    "    if best_feature == None:\n",
    "        return best_value\n",
    "    tree = {}\n",
    "    max_depth -= 1\n",
    "    if max_depth < 0:\n",
    "        return leaf_value(dataset)\n",
    "    right_sub, left_sub = split_dataset(dataset, best_feature, best_value)\n",
    "    tree['best_value'] = best_value\n",
    "    tree['best_feature'] = best_feature\n",
    "    tree['right'] = create_single_tree(right_sub, feature_num, key, max_depth)\n",
    "    tree['left'] = create_single_tree(left_sub, feature_num, key, max_depth)\n",
    "    return tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# create a random forest with n trees, k times of bootstrap, feature_num features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "def randomforest(dataset, n, k, feature_num, key = 'regression', bootstrap = True):\n",
    "    forest = []\n",
    "    for i in range(n):\n",
    "        sub_dataset = sub_samples(dataset, k, bootstrap = bootstrap)\n",
    "        forest.append(create_single_tree(sub_dataset, feature_num, key = key, max_depth = 20))\n",
    "    return forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# predict single tree using single data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "def single_tree_predict(data, tree, key = 'regression'):\n",
    "    if key == 'regression':\n",
    "        if not isinstance(tree, dict):\n",
    "            return float(tree)\n",
    "        if data[tree['best_feature']] > tree['best_value']:\n",
    "            if type(tree['right']) == 'float':\n",
    "                return tree['right']\n",
    "            else:\n",
    "                return single_tree_predict(data, tree['right'], key)\n",
    "        else:\n",
    "            if type(tree['left']) == 'float':\n",
    "                return tree['left']\n",
    "            else:\n",
    "                return single_tree_predict(data, tree['left'], key) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# predict datasets using single tree; predict datasets using rf."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "def single_tree_predict_dataset(dataset, tree, key = 'regression'):\n",
    "    m, n = dataset.shape\n",
    "    yhat = np.zeros((m, 1))\n",
    "    for i in range(m):\n",
    "        yhat[i, :] = single_tree_predict(dataset[i, :], tree, key = key)\n",
    "    return yhat\n",
    "\n",
    "def forest_predict_dataset(dataset, forest, key = 'regression'):\n",
    "    m, n = dataset.shape\n",
    "    yhat = np.zeros((m, 1))\n",
    "    for tree in forest:\n",
    "        yhat += single_tree_predict_dataset(dataset, tree, key = 'regression')\n",
    "    yhat /= len(forest)\n",
    "    return yhat        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# read in the training dataset, split it into training and cross validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "training = pd.read_csv('D:/Program Files/machine learning/Kaggle Real Projects/house price prediction/train.csv')\n",
    "features = ['OverallQual', 'GrLivArea', 'GarageCars', 'TotalBsmtSF', 'FullBath', 'TotRmsAbvGrd', 'YearBuilt', 'SalePrice']\n",
    "Training = training[features].values\n",
    "Xtrain, Xtest, Ytrain, Ytest = train_test_split(Training[:, :-1], Training[:, -1], test_size=0.33, random_state=42)\n",
    "training_dataset = np.concatenate((Xtrain, Ytrain.reshape((-1, 1))), axis = 1)\n",
    "cv_dataset = np.concatenate((Xtest, Ytest.reshape((-1, 1))), axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# create the forsest and get the correct rate on cv dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.43775933609958506"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forest = randomforest(training_dataset, 100, len(training_dataset), 20, key = 'regression', bootstrap = True)\n",
    "Yhat = forest_predict_dataset(cv_dataset, forest, key = 'regression')\n",
    "np.sum(abs(Yhat[0] - Ytest) < 30000)/len(Ytest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# predict the price on testing dataset; write to csv final file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "testing = pd.read_csv('D:/Program Files/machine learning/Kaggle Real Projects/house price prediction/test.csv')\n",
    "features = ['OverallQual', 'GrLivArea', 'GarageCars', 'TotalBsmtSF', 'FullBath', 'TotRmsAbvGrd', 'YearBuilt']\n",
    "Testing = testing[features].values\n",
    "Ypred = forest_predict_dataset(Testing, forest, key = 'regression')\n",
    "final = pd.concat([testing['Id'], pd.DataFrame(Ypred)], axis = 1)\n",
    "final.to_csv('D:/Program Files/machine learning/Kaggle Real Projects/house price prediction/prediction2.csv', index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
